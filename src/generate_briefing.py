import os
import datetime
import akshare as ak
import pandas as pd
from openai import AzureOpenAI
from azure.identity import DefaultAzureCredential

# é…ç½® Azure OpenAI
AZURE_CONFIG = {
    "managedIdentityClientId": "",
    "endpoint": "",
    "deploymentName": "gpt-4.1-mini",
    "maxTokens": 800,
    "temperature": 0.7
}

def get_date_str():
    return datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")

def fetch_market_data():
    print("æ­£åœ¨ä» AkShare è·å–å®æ—¶å¸‚åœºæ•°æ®...")
    data_summary = []
    
    # å®šä¹‰ç¼“å­˜æ–‡ä»¶è·¯å¾„
    script_dir = os.path.dirname(os.path.abspath(__file__))
    cache_file = os.path.join(script_dir, "last_successful_data.txt")

    # 1. è·å–ä¸»è¦æŒ‡æ•°è¡Œæƒ…
    try:
        # å°è¯•ä½¿ç”¨ä¸œæ–¹è´¢å¯Œæ¥å£ (stock_zh_index_spot_em)
        # æ³¨æ„ï¼šæ¥å£åç§°å¯èƒ½ä¼šéšç‰ˆæœ¬å˜åŒ–ï¼Œå¦‚æœå¤±è´¥è¯·æ£€æŸ¥ akshare æ–‡æ¡£
        indices_df = ak.stock_zh_index_spot_em()
        
        # ä¸œæ–¹è´¢å¯Œæ¥å£è¿”å›çš„ä»£ç é€šå¸¸æ˜¯çº¯æ•°å­—å­—ç¬¦ä¸²
        target_indices = {'000001': 'ä¸Šè¯æŒ‡æ•°', '399001': 'æ·±è¯æˆæŒ‡', '399006': 'åˆ›ä¸šæ¿æŒ‡'}
        
        data_summary.append("ã€å¸‚åœºè¡Œæƒ…ã€‘")
        for code, name in target_indices.items():
            row = indices_df[indices_df['ä»£ç '] == code]
            if not row.empty:
                latest = row.iloc[0]['æœ€æ–°ä»·']
                change_pct = row.iloc[0]['æ¶¨è·Œå¹…']
                data_summary.append(f"{name}: {latest} ({change_pct}%)")
        data_summary.append("")
    except AttributeError:
        # å¦‚æœ stock_zh_index_spot_em ä¸å­˜åœ¨ï¼Œå°è¯• stock_zh_index_spot_sina
        try:
            indices_df = ak.stock_zh_index_spot_sina()
            target_indices = {'sh000001': 'ä¸Šè¯æŒ‡æ•°', 'sz399001': 'æ·±è¯æˆæŒ‡', 'sz399006': 'åˆ›ä¸šæ¿æŒ‡'}
            data_summary.append("ã€å¸‚åœºè¡Œæƒ… (Sina)ã€‘")
            for code, name in target_indices.items():
                row = indices_df[indices_df['ä»£ç '] == code]
                if not row.empty:
                    latest = row.iloc[0]['æœ€æ–°ä»·']
                    change_pct = row.iloc[0]['æ¶¨è·Œå¹…']
                    data_summary.append(f"{name}: {latest} ({change_pct}%)")
            data_summary.append("")
        except Exception as e:
             print(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥ (Sina): {e}")
    except Exception as e:
        print(f"è·å–æŒ‡æ•°æ•°æ®å¤±è´¥: {e}")

    # 2. è·å–è´¢ç»æ–°é—» (è´¢è”ç¤¾ç”µæŠ¥)
    try:
        # stock_info_global_cls è´¢è”ç¤¾ç”µæŠ¥
        # ç§»é™¤ä¸æ”¯æŒçš„å‚æ•° 'days'
        news_df = ak.stock_info_global_cls()
        
        data_summary.append("ã€æœ€æ–°èµ„è®¯ã€‘")
        if not news_df.empty:
            print(f"DEBUG: æˆåŠŸè·å–åˆ° {len(news_df)} æ¡æ–°é—»ã€‚")
            first_title = news_df.iloc[0].get('title') or news_df.iloc[0].get('æ ‡é¢˜')
            first_time = news_df.iloc[0].get('time') or news_df.iloc[0].get('å‘å¸ƒæ—¶é—´')
            print(f"DEBUG: æœ€æ–°ä¸€æ¡æ–°é—»: [{first_time}] {first_title}")

            # ç¡®ä¿æŒ‰æ—¶é—´æ’åº (å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ—¶é—´æˆ–å‘å¸ƒæ—¶é—´)
            # news_df = news_df.sort_values(by='time', ascending=False) 
            
            # å–å‰ 20 æ¡
            for _, row in news_df.head(20).iterrows():
                # é€‚é…ä¸­æ–‡åˆ—å
                title = row.get('title') or row.get('æ ‡é¢˜') or ''
                content = row.get('content') or row.get('å†…å®¹') or ''
                
                if title:
                    data_summary.append(f"- {title}")
                elif content:
                    data_summary.append(f"- {content[:100]}...")
    except Exception as e:
        print(f"è·å–æ–°é—»æ•°æ®å¤±è´¥: {e}")

    # 3. è·å–æ¶¨åœè‚¡æ±  (æ–°å¢)
    try:
        zt_pool_df = None
        # å°è¯•è·å–æœ€è¿‘ 5 å¤©çš„æ•°æ® (æ‰¾åˆ°æœ€è¿‘çš„ä¸€ä¸ªäº¤æ˜“æ—¥)
        for delta in range(0, 5):
            target_date = (datetime.datetime.now() - datetime.timedelta(days=delta)).strftime("%Y%m%d")
            try:
                df = ak.stock_zt_pool_em(date=target_date)
                if not df.empty:
                    zt_pool_df = df
                    print(f"DEBUG: æˆåŠŸè·å–åˆ° {target_date} çš„æ¶¨åœæ•°æ®ï¼Œå…± {len(df)} æ¡ã€‚")
                    break
            except:
                continue
        
        data_summary.append("ã€æ¶¨åœæ¢¯é˜Ÿæ•°æ®ã€‘")
        if zt_pool_df is not None and not zt_pool_df.empty:
            # ç¡®ä¿è¿æ¿æ•°æ˜¯æ•°å­—
            if 'è¿æ¿æ•°' in zt_pool_df.columns:
                zt_pool_df['è¿æ¿æ•°'] = pd.to_numeric(zt_pool_df['è¿æ¿æ•°'], errors='coerce')
                zt_pool_df = zt_pool_df.sort_values(by='è¿æ¿æ•°', ascending=False)
            
            # å–å‰ 15 åªé¾™å¤´ (è¿æ¿æ•°é«˜çš„)
            for _, row in zt_pool_df.head(15).iterrows():
                name = row.get('åç§°')
                lb = row.get('è¿æ¿æ•°')
                first_time = row.get('é¦–æ¬¡å°æ¿æ—¶é—´')
                last_time = row.get('æœ€åå°æ¿æ—¶é—´')
                open_times = row.get('ç‚¸æ¿æ¬¡æ•°')
                industry = row.get('æ‰€å±è¡Œä¸š')
                
                # æ„é€ æè¿°ç»™ AI åˆ†æ
                data_summary.append(f"- {name} ({lb}è¿æ¿): è¡Œä¸š-{industry}, é¦–æ¬¡å°æ¿-{first_time}, æœ€åå°æ¿-{last_time}, ç‚¸æ¿-{open_times}æ¬¡")
        else:
            data_summary.append("æœªè·å–åˆ°æ¶¨åœæ•°æ®ã€‚")

    except Exception as e:
        print(f"è·å–æ¶¨åœæ•°æ®å¤±è´¥: {e}")
        
    final_text = "\n".join(data_summary)
    
    # ç®€å•çš„æœ‰æ•ˆæ€§æ£€æŸ¥ï¼šå¦‚æœå†…å®¹å¤ªçŸ­æˆ–ç¼ºå°‘å…³é”®æ¿å—ï¼Œè§†ä¸ºè·å–å¤±è´¥
    is_valid = len(final_text) > 100 and "ã€å¸‚åœºè¡Œæƒ…ã€‘" in final_text
    
    if is_valid:
        # è·å–æˆåŠŸï¼Œä¿å­˜åˆ°ç¼“å­˜
        try:
            with open(cache_file, "w", encoding="utf-8") as f:
                f.write(final_text)
            print(f"DEBUG: æœ€æ–°æ•°æ®å·²æˆåŠŸå¤‡ä»½è‡³ {cache_file}")
        except Exception as e:
            print(f"æ•°æ®å¤‡ä»½å¤±è´¥: {e}")
    else:
        # è·å–å¤±è´¥ï¼Œå°è¯•è¯»å–ç¼“å­˜
        print("âš ï¸ è­¦å‘Š: æœ¬æ¬¡è‡ªåŠ¨è·å–çš„æ•°æ®ä¼¼ä¹ä¸å®Œæ•´æˆ–ä¸ºç©ºã€‚")
        if os.path.exists(cache_file):
            print("ğŸ”„ æ­£åœ¨å°è¯•åŠ è½½ä¸Šæ¬¡æˆåŠŸçš„å¤‡ä»½æ•°æ®...")
            try:
                with open(cache_file, "r", encoding="utf-8") as f:
                    cached_text = f.read()
                if len(cached_text) > 50:
                    final_text = cached_text + "\n\n(æ³¨ï¼šä»¥ä¸Šä¸ºå†å²å¤‡ä»½æ•°æ®ï¼Œå› å®æ—¶è·å–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®æ—¶æ•ˆæ€§)"
                    print("âœ… æˆåŠŸåŠ è½½å¤‡ä»½æ•°æ®ã€‚")
            except Exception as e:
                print(f"åŠ è½½å¤‡ä»½æ•°æ®å¤±è´¥: {e}")
        else:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å¤‡ä»½æ•°æ®ã€‚")

    return final_text

def read_news_input(file_path="news_input.txt"):
    if not os.path.exists(file_path):
        return None
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()

def generate_briefing(news_content):
    # ä½¿ç”¨ Managed Identity è·å–å‡­è¯
    credential = DefaultAzureCredential(managed_identity_client_id=AZURE_CONFIG["managedIdentityClientId"])
    token_provider = lambda: credential.get_token("https://cognitiveservices.azure.com/.default").token

    client = AzureOpenAI(
        azure_endpoint=AZURE_CONFIG["endpoint"],
        azure_ad_token_provider=token_provider,
        api_version="2024-05-01-preview"
    )
    
    date_str = get_date_str()
    date_str_header = datetime.datetime.now().strftime("%Y%m%d")
    
    # å®šä¹‰æ™¨æŠ¥çš„æ ·å¼æ¨¡æ¿
    # ä¸¥æ ¼æ¨¡ä»¿"ç¿ç»„åˆå°çº¢èŠ±æ™¨è®¯"çš„æ ·å¼
    system_prompt = f"""
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¹¿å‘è¯åˆ¸æŠ•èµ„é¡¾é—®ï¼ˆæ–½æ™“æ–Œï¼Œæ‰§ä¸šè¯ä¹¦ xxxxxxxï¼‰ã€‚è¯·æ ¹æ®æä¾›çš„å¸‚åœºèµ„è®¯ï¼Œæ’°å†™ä¸€ç¯‡é£æ ¼ä¸¥æ ¼æ¨¡ä»¿â€œç¿ç»„åˆå°çº¢èŠ±æ™¨è®¯â€çš„æŠ•èµ„æ™¨æŠ¥ã€‚

    ### 1. æ ¸å¿ƒæ ·å¼è§„åˆ™ (HTML in Markdown)
    è¯·ç›´æ¥è¾“å‡ºåŒ…å« HTML æ ‡ç­¾çš„ Markdownï¼Œä»¥å®ç°å¤æ‚çš„æ’ç‰ˆå’Œé¢œè‰²ã€‚

    **å¤´éƒ¨æ’ç‰ˆ (å¿…é¡»å®Œå…¨ä¸€è‡´):**
    è¯·ä½¿ç”¨ HTML è¡¨æ ¼æ¥æ¨¡æ‹Ÿå¤´éƒ¨å¸ƒå±€ï¼š
    ```html
    <table style="width: 100%; border: none; margin-bottom: 10px;">
        <tr>
            <td style="text-align: left; width: 60%; vertical-align: bottom;">
                <span style="color: red; font-size: 24px; font-weight: bold;">ç¿ç»„åˆå°çº¢èŠ±æ™¨è®¯</span>
            </td>
            <td style="text-align: right; width: 40%; vertical-align: bottom;">
                <span style="color: red; font-weight: bold; font-size: 12px;">ç»„åˆå»ºè®®ä»…ä¾›å‚è€ƒï¼Œè‚¡å¸‚æœ‰é£é™©ï¼ŒæŠ•èµ„éœ€è°¨æ…ã€‚</span>
            </td>
        </tr>
        <tr>
            <td style="text-align: left;">
                <span style="color: blue; font-weight: bold; text-decoration: underline;">å¼ æµæ¶› å¹¿å‘è¯åˆ¸æŠ•èµ„é¡¾é—® (S0260617110030)</span>
            </td>
            <td style="text-align: right;">
                <span style="border: 1px solid black; padding: 2px; font-weight: bold;">{date_str_header}</span>
            </td>
        </tr>
    </table>
    <hr style="border-top: 2px solid black; margin-top: 0px;">
    ```

    ### 2. æ­£æ–‡å†…å®¹ä¸é¢œè‰²é€»è¾‘
    **ä¸è¦ä½¿ç”¨** "## å¸‚åœºå›é¡¾" è¿™ç§åˆ†æ®µæ ‡é¢˜ã€‚æ­£æ–‡åº”è¯¥æ˜¯ **3-4 æ®µç´§å‡‘çš„æ–‡å­—**ï¼Œæ®µè½ä¹‹é—´ç©ºä¸€è¡Œã€‚

    **é¢œè‰²ä½¿ç”¨è§„åˆ™ (éå¸¸é‡è¦):**
    *   **<font color='red'>çº¢è‰² (Red)</font>**ï¼š
        *   **ä¸Šæ¶¨** (å¦‚ "æ²ªæŒ‡ä¸Šæ¶¨", "æ”¶è·å…­è¿é˜³", "åˆ›æ–°é«˜").
        *   **åˆ©å¥½æ¶ˆæ¯** (å¦‚ "æ”¿ç­–é©±åŠ¨", "é‡ç»„", "ä¸šç»©è¶…é¢„æœŸ").
        *   **å¼ºåŠ¿æ¿å—/ä¸ªè‚¡** (å¦‚ "å®å¾·æ—¶ä»£å¤§æ¶¨", "åŠå¯¼ä½“çˆ†å‘").
        *   **ä¹è§‚è§‚ç‚¹** (å¦‚ "ç‰›å¸‚èµ·ç‚¹", "ç§¯æå¸ƒå±€").
        *   **å…³é”®å¼ºè°ƒ** (å¦‚ "æ ¸å¿ƒä¸»çº¿", "èµ„é‡‘æµå…¥").
    *   **<font color='blue'>è“è‰² (Blue)</font>**ï¼š
        *   **ä¸‹è·Œ** (å¦‚ "åˆ›ä¸šæ¿æŒ‡ä¸‹è·Œ", "å†²é«˜å›è½", "è°ƒæ•´").
        *   **åˆ©ç©º/é£é™©** (å¦‚ "æˆäº¤é¢èç¼©", "å¤–èµ„æµå‡º", "å‡æŒ").
        *   **å¼±åŠ¿æ¿å—** (å¦‚ "ç™½é…’å›è°ƒ", "åœ°äº§æ‰¿å‹").
        *   **è°¨æ…è§‚ç‚¹** (å¦‚ "éœ‡è¡æ•´ç†", "è§‚æœ›").
        *   **ä¸­æ€§/æè¿°æ€§æ•°æ®** (å¦‚ "æˆäº¤é¢ä¸è¶³8000äº¿", "æ²ªæŒ‡æŠ¥3000ç‚¹").
    *   **é»‘è‰² (Black)**ï¼š
        *   è¿æ¥è¯ã€æ™®é€šå™è¿°ã€èƒŒæ™¯æè¿°ã€‚

    ### 3. å†™ä½œç»“æ„
    *   **ç¬¬ä¸€æ®µ (å¸‚åœºå…¨æ™¯)**ï¼šæè¿°æŒ‡æ•°æ¶¨è·Œã€æˆäº¤é‡ã€åŒ—å‘èµ„é‡‘ã€å¸‚åœºæƒ…ç»ªã€‚é‡ç‚¹çªå‡ºâ€œæ¶¨â€æˆ–â€œè·Œâ€çš„å®šæ€§ã€‚
    *   **ç¬¬äºŒæ®µ (æ¿å—ä¸çƒ­ç‚¹)**ï¼šè¯¦ç»†æè¿°é¢†æ¶¨æ¿å—ï¼ˆçº¢ï¼‰å’Œé¢†è·Œæ¿å—ï¼ˆè“ï¼‰ã€‚ç»“åˆæ–°é—»è§£é‡ŠåŸå› ï¼ˆå¦‚â€œå—...æ”¿ç­–å‚¬åŒ–â€ï¼‰ã€‚
    *   **ç¬¬ä¸‰æ®µ (æ¶¨åœå¤ç›˜)**ï¼šè¯·åˆ†æã€æ¶¨åœæ¢¯é˜Ÿæ•°æ®ã€‘ï¼ŒæŒ‘é€‰ 3-5 åªä»£è¡¨æ€§ä¸ªè‚¡ï¼ˆå¦‚è¿æ¿é«˜åº¦æœ€é«˜çš„ï¼‰ï¼Œæ ‡æ³¨å…¶**æ¶¨åœæ—¶é—´**ï¼ˆå¦‚ "09:35å°æ¿"ï¼‰å’Œ**åˆ†æ—¶å½¢æ€**ï¼ˆæ ¹æ®å°æ¿æ—¶é—´å’Œç‚¸æ¿æ¬¡æ•°æ¨æ–­ï¼Œå¦‚ "æ—©ç›˜å¿«é€Ÿå°æ¿"ã€"çƒ‚æ¿å›å°"ã€"Tå­—æ¿"ï¼‰ã€‚
    *   **ç¬¬å››æ®µ (å®è§‚ä¸ç­–ç•¥)**ï¼šç»“åˆå®è§‚æ–°é—»ï¼ˆå¦‚ç¾è”å‚¨ã€å›½å†…æ”¿ç­–ï¼‰ç»™å‡ºç­–ç•¥å»ºè®®ã€‚
    *   **ç»“å°¾ (è®¢é˜…ä¿¡æ¯)**ï¼šæœ€åä¸€å¥å¿…é¡»æ˜¯è“è‰²èƒŒæ™¯æˆ–è“è‰²æ–‡å­—çš„è®¢é˜…è·¯å¾„ï¼š
        *   `<span style="background-color: blue; color: white; padding: 2px;">è®¢é˜…è·¯å¾„ï¼šæ˜“æ·˜é‡‘APP-æŠ•é¡¾-ç¿ç»„åˆ-ç¿ç»„åˆ18å· (å°çº¢èŠ±)</span>`

    ### 4. è¯­æ°”é£æ ¼
    *   ä¸“ä¸šã€å¹²ç»ƒã€é€»è¾‘æ€§å¼ºã€‚
    *   å¤šç”¨é‡‘èæœ¯è¯­ï¼ˆå¦‚â€œéœ‡è¡ä¸Šè¡Œâ€ã€â€œç»“æ„æ€§åˆ†åŒ–â€ã€â€œå­˜é‡åšå¼ˆâ€ï¼‰ã€‚
    *   **ä¸è¦**è¾“å‡º Markdown ä»£ç å—æ ‡è®° (```markdown)ï¼Œç›´æ¥è¾“å‡ºå†…å®¹ã€‚
    """

    user_prompt = f"ä»¥ä¸‹æ˜¯ä»Šæ—¥çš„å¸‚åœºèµ„è®¯ç´ æï¼š\n\n{news_content}"

    try:
        response = client.chat.completions.create(
            model=AZURE_CONFIG["deploymentName"],
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=AZURE_CONFIG["temperature"],
            max_tokens=AZURE_CONFIG["maxTokens"]
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"ç”Ÿæˆå¤±è´¥: {str(e)}"

def save_markdown(content, filename):
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"æ™¨è®­å·²ç”Ÿæˆ: {filename}")

if __name__ == "__main__":
    # 1. è·å–è‡ªåŠ¨æ•°æ®
    fetched_data = fetch_market_data()
    
    # 2. è¯»å–æ‰‹åŠ¨è¡¥å……ç´ æ (å¯é€‰)
    manual_input = read_news_input("src/news_input.txt")
    
    final_content = ""
    if fetched_data:
        final_content += fetched_data + "\n\n"
    if manual_input:
        final_content += "ã€æ‰‹åŠ¨è¡¥å……ç´ æã€‘\n" + manual_input
        
    if not final_content.strip():
        print("æœªè·å–åˆ°ä»»ä½•æ•°æ® (AkShare å¤±è´¥ä¸”æ— æ‰‹åŠ¨è¾“å…¥)ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–æ‰‹åŠ¨å¡«å…¥ src/news_input.txtã€‚")
    else:
        # 3. è°ƒç”¨ AI ç”Ÿæˆ
        print("æ­£åœ¨ç”Ÿæˆæ™¨è®­ï¼Œè¯·ç¨å€™...")
        # print(f"å‘é€ç»™ AI çš„å†…å®¹é¢„è§ˆ:\n{final_content[:500]}...") # è°ƒè¯•ç”¨
        briefing_content = generate_briefing(final_content)
        
        # 4. ä¿å­˜æ–‡ä»¶
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œç¡®ä¿æ–‡ä»¶ä¿å­˜åœ¨ src ç›®å½•ä¸‹ï¼Œæ— è®ºä»å“ªé‡Œè¿è¡Œ
        script_dir = os.path.dirname(os.path.abspath(__file__))
        output_file = os.path.join(script_dir, f"{datetime.datetime.now().strftime('%Y-%m-%d')}-Briefing.md")
        save_markdown(briefing_content, output_file)
